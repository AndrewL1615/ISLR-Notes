---
title: "3. Linear Regression"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
# Notes

## Simple Linear Regression

Y = $\beta_{0} + \beta_{1}X_{1}$ 

+ coefficients are minimized using ordinary least squares (OLS)


* **Important Assumptions**
  + assuming relationship between X and Y are linear
  + errors have constant variance (homoscedasticity)
  + errors are normally distributed with mean 0 (approximate)
  + errors independent of each other
  
* **Assessing model fit**
  + Residual Standard Error (RSE) = estimate of the SE of error term
    + measured in units of Y
  + $R^2$ statistic
    + will always increase if more variables are added
  
## Multiple Linear Regression

Y = $\beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + \cdots + \beta_{p}X_{p}$

* F-statistics used for MLR from the independent variables to reject null

* qualitiative predictors can be represented with dummy variables

* Polynomial regressions allow us to add non-linear relationships between predictor and response, but model overall is still linear

* potential issues (in addition to those of linear regression)
  + correlation of error terms
  + outliers
  + high-leverage point
  + collinearity/multicollinearity 
    + use variance inflation factor (VIF) to solve this

# Applied
```{r, eval=T, include=T}
#create a function that loads ISLR datasets
LoadLibraries = function (){
  library(ISLR)
  library(MASS)
  print("Libraries have been loaded")
}
LoadLibraries()
```

## 8)
```{r, eval=TRUE, include=T}
slr <- lm(mpg~horsepower, data = Auto)
summary(slr)
```
It seems that the predictor horsepower is significant with a negative t value and very low p value

```{r}
predict(slr, data.frame(horsepower = 98), interval = "confidence")
```
```{r}
plot(Auto$horsepower, Auto$mpg)
abline(reg = slr, col = "red") #regression line
par(mfrow=c(2,2))
plot(slr) #diagnoistics plots 
```

## 10)
```{r}
mlr <- lm(Sales~Price + Urban + US, data = Carseats)
summary(mlr)
```
Note that both Urban and US predictors are qualitative